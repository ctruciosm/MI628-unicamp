---
title: "Inferência Causal"
subtitle: "Ignorabilidade e sobreposição"
author: "Prof. Carlos Trucíos </br> ctrucios@unicamp.br"
Email: "ctrucios@unicamp.br"
institute: "Instituto de Matemática, Estatística e Computação Científica (IMECC), </br> Universidade Estadual de Campinas (UNICAMP)."
toc: true
toc-depth: 1
toc-title: "Conteúdo"
knitr:
    opts_chunk: 
      fig.align: 'center'
execute:
    message: false
    warning: false
format:
    revealjs:
        slide-number: true
        show-slide-number: print
        self-contained: false
        chalkboard: true
        width: 1600
        height: 900
        theme: [default, styles.scss]
        incremental: true
        code-fold: true
        logo: "imagens/imecc.png"
        footer: "Carlos Trucíos (IMECC/UNICAMP)  |  ME920/MI628 - Inferência Causal |  [ctruciosm.github.io](https://ctruciosm.github.io/)"
        highlight-style: "a11y"
        title-slide-attributes:
            data-background-image: "imagens/unicamp.png"
            data-background-size: 20%
            data-background-position: 99% 5%
            data-background-opacity: "1"
---



# Introdução
## Introdução

- Até agora, temos discutido como estimar efeitos causais em estudos observacionais assumindo _ignorabilidade_ e _sobreposição_.
- Contudo, na prática, ambas suposições são bastatnte fortes e são violadas na prática.
- Aprenderemos quais as implicações e como lidar com este problema.


# Diagramas
## Diagramas

- Diagramas causais ou **DAG**s (*directed acyclic graph*) foram introduzidos por [Pearl (1995).](https://academic.oup.com/biomet/article-abstract/82/4/669/251647)
- São uma ferramenta valiosa na inferência causal.
- Utilizaremos estes diagramas como uma forma intuitiva de ilustrar as relações causais entre variáveis.


## Diagramas


::: {.callout-note}
### Exemplo 1


:::: {.columns}

::: {.column width="50%"}
```{r}
DiagrammeR::grViz("
digraph {
  graph []
  node [shape = plaintext]
    X
    Z
    Y
  edge []
    X->Y
    X->Z
    Z->Y
  { rank = same; Z; Y }
}
")
```
:::

::: {.column width="50%"}
Se tivermos o diagrama ao lado e o foco for o efeito causal de $Z$ sob $Y$, estamos dizendo que o processo gerador de dados é da forma: 

$$\begin{align}
&X \sim F_X(x), \\
&Z = f_Z(X, \epsilon_Z), \\
&Y(z) = f_Y(X, z, \epsilon_y(z)),
\end{align}$$ em que $\epsilon_Z \perp\!\!\!\perp \epsilon_Y(z)$. Ademais, é fácil ver $Z \perp\!\!\!\perp Y(z) | X$
:::

::::

:::


## Diagramas



::: {.callout-note}
### Exemplo 2


:::: {.columns}

::: {.column width="50%"}
```{r}
DiagrammeR::grViz("
digraph {
  graph []
  node [shape = plaintext]
    X
    U
    Z
    Y
  edge []
    X->Y
    X->Z
    U->Y
    U->Z
    Z->Y
  { rank = same; Z; Y }
}
")
```
:::

::: {.column width="50%"}
$$\begin{align}
&X \sim F_X(x), \\
&U \sim F_U(u), \\
&Z = f_Z(X, U, \epsilon_Z), \\
&Y(z) = f_Y(X, U, z, \epsilon_y(z)),
\end{align}$$ em que $\epsilon_Z \perp\!\!\!\perp \epsilon_Y(z)$. Ademais, é fácil ver $Z \perp\!\!\!\perp Y(z) | (X, U)$ (*ignorabilidade* acontece condicionado em $(X, U)$ mas não condicionado apenas em $X$).
:::

::::

:::

$U$ é uma variável de confusão não medida.


# Avaliando inconfundibilidade
## Avaliando inconfundibilidade

A suposição de _ignorabilidade_ (também conhecida, *inconfundibilidade*) é dada por $$Z \perp\!\!\!\perp Y(1) | X \quad e \quad Z \perp\!\!\!\perp Y(0) | X,$$ o que implica que \begin{align}
P(Y(1) | Z = 1, X) & = P(Y(1) | Z = 0, X), \\
P(Y(0) | Z = 1, X) & = P(Y(0) | Z = 0, X).
\end{align}

Ou seja, que as distribuições dos contrafactuais $P(Y(1) | Z = 0, X)$ e $P(Y(0) | Z = 1, X)$ sejam as mesmas do que as distribuições dos factuais $P(Y(1) | Z = 1, X)$ e $P(Y(0) | Z = 0, X)$!.


## Avaliando inconfundibilidade


- Sem suposições adicionais, não é possível testar a suposição de _ignorabilidade_.
- Contudo, aprenderemos duas estratégias para _avaliar_ a suposição de _ignorabilidade_:
    *   *negative outcomes*
    *   *negative exposures*


## Avaliando inconfundibilidade: *negative outcomes*

- Suponha que $Yn$ é similar a $Y$ e compartilha a mesma estrutura de confusão.
- Se $Z \perp\!\!\!\perp Y(z) | X$ então $Z \perp\!\!\!\perp Yn(z) | X$
- Uma característica do *negative outcomes* é que conheceos, a priori, o efeito de $Z$ sob $Yn$: $$\tau(Z \rightarrow Yn) = \mathbb{E}[Yn(1) - Yn(0)].$$
- Qual seria um diagrama que satisfaz esses requerimentos?



## Avaliando inconfundibilidade: *negative outcomes*


<center>
```{r}
DiagrammeR::grViz("
digraph {
  graph []
  node [shape = plaintext]
    X
    Z
    Y
    Yn
  edge []
    X->Y
    X->Z
    X->Yn
    Z->Y
  { rank = same; Z; Y }
}
")
```
</center>


## Avaliando inconfundibilidade: *negative outcomes*


::: {.callout-note}
### Exemplo 1
Cornfield at al. (1959) estudaram o efeito de fumar cigarros no câncer de pulmão através de um estudo observacional. Os autores incluiram diversar covariáveis mas ainda é possível que existe uma variável de confusão não medida que pode causar vies no efeito observado.

Para fortalecer as evidências de causalidade, os autores também reportaram o efeito de fumar cigarros sob accidentes de auto (que foi perto de zero, como esperado). Assim, as análises baseadas no _negative outcomes_ fazem com que a evidência de causalidade entre fumar cigarros no câncer de pulmão de torne-se mais forte.
:::



## Avaliando inconfundibilidade: *negative outcomes*


::: {.callout-note}
### Exemplo 2
Imbens e Rubin (2015) sugerem utilizar o resultado desafado como _negative outcome._

Em muitos casos, é razoável acreditar que o resultado desafado e o resultado tem a mesma estrutura de confusão.

Como o resultado defasado acontece antes do tratamento, o efeito causal médio deve ser 0. 



:::


## Avaliando inconfundibilidade: *negative outcomes*


::: {.callout-note}
### Exemplo 3
Um estudo observacional com pessoas idosas mostrou que vacina contra a influenza reduz o risco de pneumonia/hospitalização por influenza, bem como mortalizade por todas as causas na temporarada seguinte.

Jackson et al. (2006), céticos com os resultados, realizam uma análise suplementar com _negative outcomes._

Vacinação começa outono e a transmisão da influenza é minima até o inverno. Assim, o efeito da vacinação deve ser mais proominente durante a época de influenza. Contudo, Jackson et al. (2006) encontram um efeito maior antes do período de influenza, sugerindo que o efeito observado é, na verdade, devido a variáveis de confusão não observadas.


:::


## Avaliando inconfundibilidade: *negative expousures*

- Assuma que $Zn$ é similar a $Z$ e compartilha a mesma estrutura de confusão.
- Se $Z \perp\!\!\!\perp Y(z) | X$ então $Zn \perp\!\!\!\perp Y(z) | X$
- Ademais, conhecemos, a priori, o efeito de $Zn$ sob $Y$: $$\tau(Zn \rightarrow Y) = \mathbb{E}[Y(1^n) - Y(0^n)].$$
- Qual seria o dirgamra que satisfaz estes requerimentos?



## Avaliando inconfundibilidade: *negative expousures*


<center>
```{r}
DiagrammeR::grViz("
digraph {
  graph []
  node [shape = plaintext]
    X
    Z
    Y
    Zn
  edge []
    X->Y
    X->Z
    X->Zn
    Z->Y
  { rank = same; Z; Y }
}
")
```
</center>


## Avaliando inconfundibilidade: *negative expousures*


::: {.callout-note}
### Exemplo 4
Sanderson et al. (2017) dão muitos exemplos de *negative expousures* na determinação do efeito da exposição intrauterina nos resultados posteriores, comparando a associação da exposição materna durante a gravidez com o resultado de interesse, com a associação da exposição paterna com o mesmo resultado. Eles revisam estudos sobre o efeito do tabagismo materno e paterno nos resultados dos filhos, e estudos sobre o efeito do IMC materno e paterno no IMC dos filhos e no transtorno do espectro do autismo. Nestes exemplos, esperamos que a associação da exposição materna com o resultado seja maior do que a da exposição paterna com o desfecho.

:::


## Avaliando inconfundibilidade:

### Alguns comentários:

- Testar  inconfundibilidade não é possível, mas podemos utilizar _negative outcomes_ ou _negative exposures_ como análise suplementar a fortalecer a nossa evidência sobre causalidade.
- Contudo, utilizar esta abordagem não é trivial, principalmente, por dois motivos:
    *   Requer mais dados (que nem sempre teremos)
    *   Requer um amplo conhecimento do problema em análise para saber escolher bem $Yn$ ou $Zn$.
    

# Sobreajuste
## Sobreajuste

Nas aulas anteriores discutimos como estimar efeitos causais sob e suposição de inconfundibilidade ou _ignorabilidade:_

$$Z \perp\!\!\!\perp \{ Y(1), Y(0) \} | X$$


. . . 

#### Qual o conjunto "certo" de variáveis $X$?

- Todas as variáveis pre-tratamento [Rosembaum (2002) e Rubin (2007)].
- Contudo, não todos concordam com esta abordagem. De fato, Pearl da dois contraexemplos.


## Sobreajuste

### M-vies

<center>
```{r}
DiagrammeR::grViz("
digraph {
  graph []
  node [shape = plaintext]
    U1
    U2
    X
    Z
    Y
  edge []
    U1->Z
    U1->X
    U2->X
    U2->Y
  { rank = same; Z; Y }
}
")
```
</center>

em que $X$ é observado mas $U1$ e $U2$ não são.


## Sobreajuste

### M-vies

- $U1 \perp\!\!\!\perp U2$, 
- $Z = f_Z(U1, \epsilon_z)$, 
- $X = f_X(U1, U2, \epsilon_x)$,
- $Y = Y(z) = f_Y(U2, \epsilon_y)$, 
- $(\epsilon_z, \epsilon_x, \epsilon_y)$ são termos aleatórios independentes.

. . . 

Note que se mudarmos o valor de $Z$, o valor de $Y$ não muda. Ou seja, o verdadeiro efeito causal de de $Z$ sob $Y$ é zero. 

. . . 

Ademais, $$\mathbb{E}[Y | Z = 1] - \mathbb{E}[Y | Z = 0] = 0$$


## Sobreajuste

### M-vies
Suponha que:

- $X = aU_1 + b U_2 + \epsilon_X$,
- $Z = cU_1 + \epsilon_Z$,
- $Y = dU_2 + \epsilon_Y$,
- $(U_1, U_2, \epsilon_X, \epsilon_Z, \epsilon_Y) \sim N(0,1)$

. . . 

$$\mathbb{C}ov(Z, Y) = \mathbb{C}ov(cU_1 + \epsilon_Z, dU_2 + \epsilon_Y) = 0$$

. . . 


Contudo, $$\rho_{ZY|X} = \dfrac{\rho_{ZY} - \rho_{ZX}\rho_{YX}}{\sqrt{1 - \rho^2_{ZX}} \sqrt{1 - \rho^2_{YX}}} \propto -abdc$$

## Sobreajuste

### M-vies


```{r}
#| echo: true
n <- 10^6
U1 <- rnorm(n)
U2 <- rnorm(n)
X <- U1 + U2 + rnorm(n)
Y <- U2 + rnorm(n)
Z <- U1 + rnorm(n)
tau <- summary(lm(Y ~ Z))$coef[2, 1]
tau_adj <- summary(lm(Y ~ Z + X))$coef[2, 1]
round(c(tau, tau_adj), 3)
```

. . . 


<center>
[O estimador simples é não viesado, mas o ajustado por covariáveis é viesado.]{style="color:red;"}
</center>


## Sobreajuste
### Z-vies


<center>
```{r}
DiagrammeR::grViz("
digraph {
  graph []
  node [shape = plaintext]
    U
    X
    Z
    Y
  edge []
    U->Z
    U->Y
    X->Z
    Z->Y
  { rank = same; X; Z; Y }
}
")
```
</center>


## Sobreajuste
### Z-vies

Suponha que:

- $Z = aX + bU + \epsilon_Z,$
- $Y(z) = \tau z + cU + \epsilon_y$
- $(U, X, \epsilon_Z, \epsilon_Y) \sim N(0,1)$





## Referências

::: {.nonincremental}

- Peng Ding (2023). A First Course in Causal Inference. Capítulo 16.
- Lipsitch, M., Tchetgen, E. T., & Cohen, T. (2010). Negative controls: a tool for detecting confounding and bias in observational studies. Epidemiology, 21(3), 383-388.

:::