---
title: "Inferência Causal"
subtitle: "Sobreposição"
author: "Prof. Carlos Trucíos </br> ctrucios@unicamp.br"
Email: "ctrucios@unicamp.br"
institute: "Instituto de Matemática, Estatística e Computação Científica (IMECC), </br> Universidade Estadual de Campinas (UNICAMP)."
toc: true
toc-depth: 1
toc-title: "Conteúdo"
knitr:
    opts_chunk: 
      fig.align: 'center'
execute:
    message: false
    warning: false
format:
    revealjs:
        slide-number: true
        show-slide-number: print
        self-contained: false
        chalkboard: true
        width: 1600
        height: 900
        theme: [default, styles.scss]
        incremental: true
        code-fold: true
        logo: "imagens/imecc.png"
        footer: "Carlos Trucíos (IMECC/UNICAMP)  |  ME920/MI628 - Inferência Causal |  [ctruciosm.github.io](https://ctruciosm.github.io/)"
        highlight-style: "a11y"
        title-slide-attributes:
            data-background-image: "imagens/unicamp.png"
            data-background-size: 20%
            data-background-position: 99% 5%
            data-background-opacity: "1"
---



# Introdução
## Introdução

- As técnicas para estudos observacionais discutidas anteriormente baseiam-se em duas suposições: _ignorabilidade_ ($Z \perp\!\!\!\perp  \{ Y(1), Y(0)\} | X$) e _sobreposição_ ($0 < e(X) < 1$).
- Já discutimos como agir quando a hipótese de ignorabilidade não parece apropriada.
- Hoje discutiremos o que fazer quando a hipótese de sobreposição não parece apropriada.




# Implicações
## Implicações

- Se algumas unidades tem $e(X) = 0$ ou $e(X) = 1$ é dificil pensarmos na existência do contrafactual.
- Mesmo se $e(X)$ não for exatamente 0 nem 1, $\hat{e}(X)$ pode estar muito perto de 0 ou 1, causando instabilidade nos estimadores.
- Uma alternativa disso é assumimos _sobreposição forte_, ou seja que $$\eta \leq e(X) \leq 1 - \eta,     \quad, \eta \in (0, 1/2).$$ Contudo, essa suposição tem consequências não triviais (ver Teorema 20.1 do livro texto).
- Quando _sobreposição forte_ não acontece, uma prática commum é o _Trimming_ do $\hat{e}(X),$ mas esta alternativa está longe de ser ótima.
- Uma outra alternativa é a regressão descontinuada.


# Regressão descontinuada
## Regressão descontinuada

- Seja $X \in \mathbb{R}$, um mecanismno (extremo) de atribuição de tratamento pode ser dado por $$Z = \mathbb{I}(X \geq x_0),$$ para algum valor $x_0$ pre-determinado.
- Isto garante, automaticamente, que ignorabilidade aconteça.
- Contudo, a suposição de sobreposição é violada pois $$e(X) = P(Z = 1 | X) = \mathbb{I}(X \geq x_0).$$

. . . 

<center>
[Será que o mecanismo de aribuição de tratamento definido acima é algo irreal?]{style="color:red;"}
</center>


## Regressão descontinuada: exemplos

::: {.callout-note}
### Exemplo 1
Thistlethwaite e Campbell (1960), estudam o efeito dos estudantes obterem um certificado de mérito sob o plano de carreira. A obtenção ou não do certificado depende de se pontuação no teste de qualificação está acima de um determinado valor de corte.
:::

. . . 



::: {.callout-note}
### Exemplo 2
Bor et al. (2014) utilizaram regressão descontinuidade para estudar o efeito de iniciar pacientes com HIV com antirretrovirais sob a sua mortalidade. O tratamento é iniciado quando contagem de globulos brancos é menor do que 200/μL.
:::


. . . 

 
::: {.callout-note}
### Exemplo 3
Carpenter e Dobkin (2009) estudaram o efeito do consumo de álcool sobre mortalidade e utilizam a idade minima legal para beber como uma descontinuidade para o consumo de álcool.
:::


## Regressão descontinuada: Formulação

Regressão descontinuada pode identificar o efeito causal médio local para um determinado valor de corte $x_0$: $$\tau(x_0) = \mathbb{E} [Y(1) - Y(0) | X = x_0],$$ em que $X$ é a variável que determina o tratamento e é conhecida como _running variable._

## Regressão descontinuada: Formulação

Se $\mathbb{E}[Y(1) | X = x]$ for contínua pela direita em $x_0$, temos que \begin{align}
\mathbb{E}[Y(1) | X = x_0] &= \lim_{\epsilon \rightarrow 0^{+}} \mathbb{E}[Y(1) | X = x_0 + \epsilon] \\
& = \lim_{\epsilon \rightarrow 0^{+}} \mathbb{E}[Y(1) | Z = 1, X = x_0 + \epsilon] \\
& = \lim_{\epsilon \rightarrow 0^{+}} \mathbb{E}[Y | Z = 1, X = x_0 + \epsilon].
\end{align}

. . . 

De forma semelhante, se  $\mathbb{E}[Y(0) | X = x]$ for contínuo pela esquerda em $x_0$,  $$\mathbb{E}[Y(1) | X = x_0] = \lim_{\epsilon \rightarrow 0^{+}} \mathbb{E}[Y | Z = 0, X = x_0 - \epsilon].$$


## Regressão descontinuada: Formulação


::: {.callout-tip}
### Teorema
Asuma que o mecanismo de atribuicao de tratamento é dado por $Z = \mathbb{I}(X \geq x_0),$ em que $x_0$ é um ponto de corte pre-definido. Assuma também que $\mathbb{E}[Y(1) | X = x]$ é contínuo pela direita em $x_0$ e $\mathbb{E}[Y(0) | X = x]$  é contínuo pela esquerda em $x_0$. Então, o efeito causal médio (local em $X = x_0$) é dado por $$\tau(x_0) = \lim_{\epsilon \rightarrow 0^{+}} \mathbb{E}[Y | Z = 1, X = x_0 + \epsilon] -  \lim_{\epsilon \rightarrow 0^{+}} \mathbb{E}[Y | Z = 0, X = x_0 - \epsilon].$$

:::

. . . 

Note que o parâmetro $\tau(x_0)$ envolve apenas a distribuição dos observáveis e então é identificável não parametricamente.


# Regressão perto da fronteira
## Regressão perto da fronteira

Se tivermos sorte, uma análise gráfica nos ajudará a enxergar o efeito causal para um determinado ponto de corte $x_0$. Contudo, isto não sempre é possível na prática.


. . .

### Ilustração

- Simularemos quatro conjunto de dados. 
- Todos os _datasets_ serão com discontinuidade em $x_0 = 0$.
- Veremos se a inspeção gráfica é suficiente por si só.



## Regressão perto da fronteira

```{r}
#| echo: true
par(mfrow = c(2, 2), mar = c(4, 2, 1, 1), mgp = c(2,1,0))
n   = 500
x   = rnorm(n)
y0  = x + rnorm(n, 0, 0.5)
y1  = y0 + 5
z   = (x>=0)
y   = z*y1 + (1-z)*y0
plot(y0 ~ x, col = "grey", pch = 19, cex = 0.3,
     ylim = c(min(y), max(y)),
     xlab = "X", ylab = "")
points(y1 ~ x, col = "grey", pch = 19, cex = 0.3)
points(y ~ x, col = "black", pch = 19, cex = 0.3)
abline(v = 0, lty = 2)


y0  = x + rnorm(n, 0, 0.5)
y1  = y0 + 1
z   = (x>=0)
y   = z*y1 + (1-z)*y0
plot(y0 ~ x, col = "grey", pch = 19, cex = 0.3,
     ylim = c(min(y), max(y)),
     ylab = "", xlab = "X")
points(y1 ~ x, col = "grey", pch = 19, cex = 0.3)
points(y ~ x, col = "black", pch = 19, cex = 0.3)
abline(v = 0, lty = 2)


y0  = 2*x + rnorm(n, 0, 0.5)
y1  = 5 + 0.5*x + rnorm(n, 0, 0.5)
z   = (x>=0)
y   = z*y1 + (1-z)*y0
plot(y0 ~ x, col = "grey", pch = 19, cex = 0.3,
     ylim = c(min(y), max(y)),
     ylab = "", xlab = "X")
points(y1 ~ x, col = "grey", pch = 19, cex = 0.3)
points(y ~ x, col = "black", pch = 19, cex = 0.3)
abline(v = 0, lty = 2)



y0  = 2*x + rnorm(n, 0, 0.5)
y1  = 1 + 0.5*x + rnorm(n, 0, 0.5)
z   = (x>=0)
y   = z*y1 + (1-z)*y0
plot(y0 ~ x, col = "grey", pch = 19, cex = 0.3,
     ylim = c(min(y), max(y)),
     ylab = "", xlab = "X")
points(y1 ~ x, col = "grey", pch = 19, cex = 0.3)
points(y ~ x, col = "black", pch = 19, cex = 0.3)
abline(v = 0, lty = 2)
```


## Regressão perto da fronteira

Suponhamos que $$\mathbb{E}(Y | Z = 1, X = x) = \gamma_1 + \beta_1 x\quad e \quad \mathbb{E}(Y | Z = 0, X = x) = \gamma_0 + \beta_0 x.$$

. . . 

Através de MQO podemos ajustar ambas as retas de regressão e obtermos $$\hat{\gamma}_1 + \hat{\beta}_1 x \quad e \quad \hat{\gamma}_0 + \hat{\beta}_0 x.$$

. . . 

Então, o efeito causal no ponto $X = x_0$ é dado por $$\hat{\tau}(x_0) = (\hat{\gamma}_1 - \hat{\gamma}_0) + (\hat{\beta}_1 - \hat{\beta}_0) x_0$$

. . . 

## Regressão perto da fronteira


- $\hat{\tau} (x_0)$ pode também ser obtido como o coeficiente associado a $Z$ da regressão $Y \sim \{1, Z, X - x_0, Z(X-x_0) \}$.
- Equivalentemente, $\hat{\tau} (x_0)$ pode também ser obtido como o coeficiente associado a $Z$ da regressão $Y \sim \{1, Z, R, L \}$, em que $R = max(X-x_0, 0)$ e $L = min(X-x_0, 0)$.
- A recomendação é ajustar a regressão considerando apenas s observações locais perto do ponto de corte.
- Como a escolha dos pontos locais é fundamental na regressão descontinuada, o commum é reportar intervalos de confiança para várias escolhas dos pontos locais (pode até servir como una análise de sensibilidade).



# Exemplo
## Exemplo

::: {.callout-note}
### Exemplo
Lee (2008) estuda a _vantagem de já serem previamente eleitos_ no congresso dos Estados Unidos. "Eleitos são aqueles políticos que tiveram sucesso na eleição prévia. Se aquilo que os torna bem sucedidos é persistente ao longo do tempo, deve-se esperar que tenham um pouco mais de sucesso quando concorrerem à reeleição."

Este é um problema de inferência causal no qual regressão descontinuada é uma estratégia interessante.

A variável $X$ (*running variable*) é o voto obtido nas eleições anteriores (centrado no 0) e o resultado ($Y$) é o voto na eleição atual com unidades sendo os distritos eleitorais. O tratamento ($Z$) é uma binária indicando se foi eleito na eleição anterior no distrito. 

:::

. . . 



```{r}
#| echo: true
library(dplyr)
house <- read.csv("datasets/house.csv")[, -1]
glimpse(house)
```

## Exemplo

```{r}
#| echo: true
plot(x ~ y, data = house, pch = 19, cex = 0.1)
```

. . . 

Utilizaremos a função `rdrobust()` do pacote `rdrobust` que nos ajudará na nossa escolha dos pontos locais. A função implementa vários métodos de **pontos locais**.

## Exemplo

```{r}
#| echo: true
library(rdrobust)
model <- rdrobust(house$y, house$x)
cbind(model$coef, model$ci)
```

. . . 

Também é possível fazer a regressão local por MQO:

```{r}
#| echo: true
house$z <- (house$x >= 0)
hh <- seq(0.05, 1, 0.01)
local_regression <- sapply(hh, function(h) {
  modelo <- lm(y ~ z + x + z*x, data = house, subset = abs(x) <= h)
  cbind(modelo$coef[2], confint(modelo, 'zTRUE'))
})
local_regression <- t(local_regression)
```

## Exemplo
```{r}
#| echo: true
library(ggplot2)
dados <- data.frame(h = hh, point = local_regression[, 1], int_inf = local_regression[, 2], int_sup = local_regression[, 3])
ggplot(data = dados) +
  geom_point(aes(x = h, y = point)) + 
  geom_point(aes(x = h, y = int_inf), color = "red") + 
  geom_point(aes(x = h, y = int_sup), color = "red") 
```


## Comentários Finais

- Escolha dos vizinhos perto de $x_0$
- Regressão discontinuada assume que $\mathbb{E}(Y(1) | Z = x)$ é continuo pela direita e $\mathbb{E}(Y(0) | Z = x)$ é contínuo pela esquerda. 
- Essa suposição pode algumas vezes ser violada. Por exemplo:
    *   Se a taxa de mortalidade sofrer um "pulo" aos 18 anos, não poderiamos atribuir esse pulo à mudança do comportamento devido a que agora o cidadão pode beber.
    *   Na prática, é dificil verificar se a suposição é valida ou não.
    *   Existe um teste proposto por [McCrary (2008)](https://www.sciencedirect.com/science/article/pii/S0304407607001133?casa_token=9L-GxrsCFNIAAAAA:90XM_1Xxtz5SKvgNcFIDKVq2zj7yZWtsYKNMqY8M0GIJvjs74X3FWfU6Y7N3QuLkPORKevQcxIM) para testar a validez da regressão descontinuada.



## Referências



::: {.nonincremental}

- Peng Ding (2023). A First Course in Causal Inference. Capítulo 20.

:::