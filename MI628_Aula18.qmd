---
title: "Inferência Causal"
subtitle: "Sobreposição"
author: "Prof. Carlos Trucíos </br> ctrucios@unicamp.br"
Email: "ctrucios@unicamp.br"
institute: "Instituto de Matemática, Estatística e Computação Científica (IMECC), </br> Universidade Estadual de Campinas (UNICAMP)."
toc: true
toc-depth: 1
toc-title: "Conteúdo"
knitr:
    opts_chunk: 
      fig.align: 'center'
execute:
    message: false
    warning: false
format:
    revealjs:
        slide-number: true
        show-slide-number: print
        self-contained: false
        chalkboard: true
        width: 1600
        height: 900
        theme: [default, styles.scss]
        incremental: true
        code-fold: true
        logo: "imagens/imecc.png"
        footer: "Carlos Trucíos (IMECC/UNICAMP)  |  ME920/MI628 - Inferência Causal |  [ctruciosm.github.io](https://ctruciosm.github.io/)"
        highlight-style: "a11y"
        title-slide-attributes:
            data-background-image: "imagens/unicamp.png"
            data-background-size: 20%
            data-background-position: 99% 5%
            data-background-opacity: "1"
---



# Introdução
## Introdução

- As técnicas para estudos observacionais discutidas anteriormente baseiam-se em duas suposições: _ignorabilidade_ ($Z \perp\!\!\!\perp  \{ Y(1), Y(0)\} | X$) e _sobreposição_ ($0 < e(X) < 1$).
- Já discutimos como agir quando a hipótese de ignorabilidade não parece apropriada.
- Hoje discutiremos o que fazer quando a hipótese de sobreposição não parece apropriada.




# Implicações
## Implicações

- Se algumas unidades tem $e(X) = 0$ ou $e(X) = 1$ é dificil pensarmos na existência do contrafactual.
- Mesmo se $e(X)$ não for exatamente 0 nem 1, $\hat{e}(X)$ pode estar muito perto de 0 ou 1, causando instabilidade nos estimadores.
- Uma alternativa disso é assumimos _sobreposição forte_, ou seja que $$\eta \leq e(X) \leq 1 - \eta,     \quad, \eta \in (0, 1/2).$$ Contudo, essa suposição tem consequências não triviais (ver Teorema 20.1 do livro texto).
- Quando _sobreposição forte_ não acontece, uma prática commum é o _Trimming_ do $\hat{e}(X),$ mas esta alternativa está longe de ser ótima.
- Uma outra alternativa é a regressão descontinuada.


# Regressão descontinuada
## Regressão descontinuada

- Seja $X \in \mathbb{R}$, um mecanismno (extremo) de atribuição de tratamento pode ser dado por $$Z = \mathbb{I}(X \geq x_0),$$ para algum valor $x_0$ pre-determinado.
- Isto garante, automaticamente, que ignorabilidade aconteça.
- Contudo, a suposição de sobreposição é violada pois $$e(X) = P(Z = 1 | X) = \mathbb{I}(X \geq x_0).$$

. . . 

<center>
[Será que o mecanismo de aribuição de tratamento definido acima é algo irreal?]{style="color:red;"}
</center>


## Regressão descontinuada: exemplos

::: {.callout-note}
### Exemplo 1
Thistlethwaite e Campbell (1960), estudam o efeito dos estudantes obterem um certificado de mérito sob o plano de carreira. A obtenção ou não do certificado depende de se pontuação no teste de qualificação está acima de um determinado valor de corte.
:::

. . . 



::: {.callout-note}
### Exemplo 2
Bor et al. (2014) utilizaram regressão descontinuidade para estudar o efeito de quando iniciar pacientes com HIV com antirretrovirais sob a sua mortalidade. O tratamento é iniciado quando contagem de globulos brancos é menor do que 200/μL.
:::


. . . 

 
::: {.callout-note}
### Exemplo 3
Carpenter e Dobkin (2009) estudaram o efeito do consumo de álcool sobre mortalidade e utilizam a idade minima legal para beber como uma descontinuidade para o consumo de álcool.
:::


## Regressão descontinuada: Formulação

Regressão descontinuada pode identificar o efeito causal médio local para um determinado valor de corte $x_0$: $$\tau(x_0) = \mathbb{E} [Y(1) - Y(0) | X = X_0],$$ em que $X$ é a variável que determina o tratamento e é conhecida como _running variable._

## Regressão descontinuada: Formulação

Se $\mathbb{E}[Y(1) | X = x]$ for contínua pela direita em $x_0$, temos que \begin{align}
\mathbb{E}[Y(1) | X = x_0] &= \lim_{\epsilon \rightarrow 0^{+}} \mathbb{E}[Y(1) | X = x_0 + \epsilon] \\
& = \lim_{\epsilon \rightarrow 0^{+}} \mathbb{E}[Y(1) | Z = 1, X = x_0 + \epsilon] \\
& = \lim_{\epsilon \rightarrow 0^{+}} \mathbb{E}[Y | Z = 1, X = x_0 + \epsilon].
\end{align}

. . . 

De forma semelhante, se  $\mathbb{E}[Y(0) | X = x]$ for contínuo pela esquerda,  $$\mathbb{E}[Y(1) | X = x_0] = \lim_{\epsilon \rightarrow 0^{+}} \mathbb{E}[Y | Z = 0, X = x_0 - \epsilon].$$


## Regressão descontinuada: Formulação


::: {.callout-tip}
Asuma que o mecanismo de atribuicao de tratamento é dado por $Z = \mathbb{I}(X \geq x_0),$ em que $x_0$ é um ponto de corte pre-definido. Assuma também que $\mathbb{E}[Y(1) | X = x]$ é contínuo pela direita em $x_0$ e $\mathbb{E}[Y(0) | X = x]$  é contínuo pela esquerda em $x_0$. Então, o efeito causal médio (local em $X = x_0$) é dado por $$\tau(x_0) = \lim_{\epsilon \rightarrow 0^{+}} \mathbb{E}[Y | Z = 1, X = x_0 + \epsilon] -  \lim_{\epsilon \rightarrow 0^{+}} \mathbb{E}[Y | Z = 0, X = x_0 - \epsilon].$$

:::

. . . 

Note que o parâmetro $\tau(x_0)$ envolve apenas a distribuição dos observáveis e então é identificável não parametricamente.


# Regressão perto da fronteira
## Regressão perto da fronteira

Se termos sorte, uma análise gráfica nos ajudará a enxergar o efeito causal para um determinado ponto de corte $x_0$. Contudo, isto não sempre é possível na prática.


. . .

Para ilustrar isto, simularemos quatro conjunto de dados. Todos com discontinuidade em $x_0 = 0$ e veremos se a inspeção gráfica é suficiente por si só.



## Regressão perto da fronteira

```{r}
#| echo: true
par(mfrow = c(2, 2), mar = c(4, 2, 1, 1), mgp = c(2,1,0))
n   = 500
x   = rnorm(n)
y0  = x + rnorm(n, 0, 0.5)
y1  = y0 + 5
z   = (x>=0)
y   = z*y1 + (1-z)*y0
plot(y0 ~ x, col = "grey", pch = 19, cex = 0.3,
     ylim = c(min(y), max(y)),
     xlab = "X", ylab = "")
points(y1 ~ x, col = "grey", pch = 19, cex = 0.3)
points(y ~ x, col = "black", pch = 19, cex = 0.3)
abline(v = 0, lty = 2)


y0  = x + rnorm(n, 0, 0.5)
y1  = y0 + 1
z   = (x>=0)
y   = z*y1 + (1-z)*y0
plot(y0 ~ x, col = "grey", pch = 19, cex = 0.3,
     ylim = c(min(y), max(y)),
     ylab = "", xlab = "X")
points(y1 ~ x, col = "grey", pch = 19, cex = 0.3)
points(y ~ x, col = "black", pch = 19, cex = 0.3)
abline(v = 0, lty = 2)


y0  = 2*x + rnorm(n, 0, 0.5)
y1  = 5 + 0.5*x + rnorm(n, 0, 0.5)
z   = (x>=0)
y   = z*y1 + (1-z)*y0
plot(y0 ~ x, col = "grey", pch = 19, cex = 0.3,
     ylim = c(min(y), max(y)),
     ylab = "", xlab = "X")
points(y1 ~ x, col = "grey", pch = 19, cex = 0.3)
points(y ~ x, col = "black", pch = 19, cex = 0.3)
abline(v = 0, lty = 2)



y0  = 2*x + rnorm(n, 0, 0.5)
y1  = 1 + 0.5*x + rnorm(n, 0, 0.5)
z   = (x>=0)
y   = z*y1 + (1-z)*y0
plot(y0 ~ x, col = "grey", pch = 19, cex = 0.3,
     ylim = c(min(y), max(y)),
     ylab = "", xlab = "X")
points(y1 ~ x, col = "grey", pch = 19, cex = 0.3)
points(y ~ x, col = "black", pch = 19, cex = 0.3)
abline(v = 0, lty = 2)
```





## Referências



::: {.nonincremental}

- Peng Ding (2023). A First Course in Causal Inference. Capítulo 20.

:::